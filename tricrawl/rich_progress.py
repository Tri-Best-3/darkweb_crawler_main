"""
Rich Progress Bar Extension
- Live progress display (Items, Requests, Errors)
- Startup status summary (Discord, Supabase connection)
- Recent item preview
- Final stats summary
"""
import os
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeElapsedColumn
from rich.console import Console, Group
from rich.panel import Panel
from rich.live import Live
from scrapy import signals
from scrapy.exceptions import NotConfigured


class RichProgress:
    """Scrapy í¬ë¡¤ë§ ì§„í–‰ ìƒí™©ì„ Rich Progress Barë¡œ í‘œì‹œ."""

    def __init__(self, crawler):
        self.crawler = crawler
        self.stats = crawler.stats
        self.console = Console()
        
        # Progress Bar ì„¤ì •
        self.progress = Progress(
            SpinnerColumn("dots"),  # ë” ë¶€ë“œëŸ¬ìš´ ìŠ¤í”¼ë„ˆ
            TextColumn("[bold cyan]{task.description}[/bold cyan]"),
            BarColumn(bar_width=25),
            TimeElapsedColumn(),
            TextColumn("{task.fields[info]}"),
            console=self.console,
            transient=False,
        )
        self.task_id = None
        
        # ìƒíƒœ í‘œì‹œìš©
        self.last_item_text = "[dim]ğŸ”§ ì´ˆê¸°í™” ì¤‘...[/dim]"
        self.first_response = False  # ì²« ì‘ë‹µ ì—¬ë¶€
        
        # Live ì»¨í…ìŠ¤íŠ¸
        self.live = None

    @classmethod
    def from_crawler(cls, crawler):
        if not crawler.settings.getbool("RICH_PROGRESS_ENABLED", True):
            raise NotConfigured

        ext = cls(crawler)
        crawler.signals.connect(ext.spider_opened, signal=signals.spider_opened)
        crawler.signals.connect(ext.spider_closed, signal=signals.spider_closed)
        crawler.signals.connect(ext.item_scraped, signal=signals.item_scraped)
        crawler.signals.connect(ext.item_dropped, signal=signals.item_dropped)
        crawler.signals.connect(ext.response_received, signal=signals.response_received)
        crawler.signals.connect(ext.request_scheduled, signal=signals.request_scheduled)
        return ext

    def _print_startup_status(self, spider):
        """Print startup configuration summary."""
        settings = self.crawler.settings
        
        # Discord ìƒíƒœ
        discord_url = settings.get("DISCORD_WEBHOOK_URL")
        discord_status = "[green]âœ“ ì—°ê²°ë¨[/green]" if discord_url else "[yellow]âš  ë¯¸ì„¤ì •[/yellow]"
        
        # Supabase ìƒíƒœ
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_status = "[green]âœ“ ì—°ê²°ë¨[/green]" if supabase_url else "[red]âœ— ë¯¸ì„¤ì •[/red]"
        
        # ì¤‘ë³µ ID ë¡œë“œ ê°œìˆ˜ (dedup pipelineì—ì„œ ì„¤ì •)
        loaded_ids = self.stats.get_value("dedup/loaded_ids", 0)
        dedup_status = f"[cyan]{loaded_ids:,}[/cyan]ê°œ" if loaded_ids else "[dim]0ê°œ[/dim]"
        
        # Log íŒŒì¼ (ê²½ë¡œ ì¶•ì•½)
        log_file = settings.get("LOG_FILE", "")
        if log_file:
            log_file_display = "..." + str(log_file)[-35:] if len(str(log_file)) > 35 else str(log_file)
        else:
            log_file_display = "[dim]ì—†ìŒ[/dim]"
        
        status_lines = [
            f"ğŸ•·ï¸  [bold]ìŠ¤íŒŒì´ë”:[/bold] {spider.name}",
            f"ğŸ“¢  [bold]ë””ìŠ¤ì½”ë“œ ì•Œë¦¼:[/bold] {discord_status}",
            f"ğŸ’¾  [bold]Supabase DB:[/bold] {supabase_status}",
            f"ğŸ”  [bold]ì¤‘ë³µ ID ë¡œë“œ:[/bold] {dedup_status}",
            f"ğŸ“  [bold]ë¡œê·¸ íŒŒì¼:[/bold] {log_file_display}",
        ]
        
        self.console.print(Panel(
            "\n".join(status_lines),
            title="[bold blue]ğŸš€ Start Crawling[/bold blue]",
            border_style="blue",
            padding=(0, 1),
            width=50,
        ))

    def _build_display(self):
        """Create display group (Progress Bar + Recent Items)."""
        from rich.text import Text
        return Group(
            self.progress,
            Text.from_markup(f"  {self.last_item_text}"),
        )

    def spider_opened(self, spider):
        """Initialize progress bar on spider open."""
        self._print_startup_status(spider)
        self.console.print()  # ë¹ˆ ì¤„
        
        self.task_id = self.progress.add_task(
            "Crawling",
            total=None,
            info="[dim]Initializing...[/dim]"
        )
        
        # Live ì»¨í…ìŠ¤íŠ¸ ì‹œì‘ (ë¶€ë“œëŸ¬ìš´ ì—…ë°ì´íŠ¸)
        self.live = Live(
            self._build_display(),
            console=self.console,
            refresh_per_second=10,
            transient=False,
        )
        self.live.start()

    def spider_closed(self, spider):
        """Stop progress bar and print final stats."""
        if self.live:
            self.live.stop()
        
        scraped = self.stats.get_value("item_scraped_count", 0)
        dropped = self.stats.get_value("item_dropped_count", 0)
        req_count = self.stats.get_value("downloader/request_count", 0)
        resp_count = self.stats.get_value("downloader/response_count", 0)
        err_count = self.stats.get_value("log_count/ERROR", 0)
        
        pre_dedup_skipped = self.stats.get_value('pre_dedup/skipped', 0)
        discovered = self.stats.get_value('items/discovered', 0)
        
        # ê°„ë‹¨í•˜ê²Œ "ìµœì‹  Xê±´ ì „ë¶€ ê¸°ì¡´" í‘œì‹œ
        if discovered > 0 and pre_dedup_skipped == discovered:
            pre_dedup_text = f"ìµœì‹  {discovered}ê±´ ì¼ì¹˜(ì¡°ê¸° ì¢…ë£Œ)"
        elif discovered > 0:
            pre_dedup_text = f"ì¡°íšŒ {discovered}ê±´ ì¤‘ {pre_dedup_skipped}ê±´ ì¼ì¹˜"
        elif pre_dedup_skipped > 0:
            pre_dedup_text = f"{pre_dedup_skipped}ê±´ ì¼ì¹˜"
        else:
            pre_dedup_text = "ì—†ìŒ"
        
        result_lines = [
            f"ğŸ“¦  [bold]ì‹ ê·œ ìˆ˜ì§‘:[/bold] [bold green]{scraped}[/bold green]ê±´",
            f"ğŸ”„  [bold]Pre-Dedup:[/bold] {pre_dedup_text}",
            f"ğŸ—‘ï¸   [bold]ì¤‘ë³µ/í•„í„°:[/bold] {dropped}ê±´",
            f"ğŸŒ  [bold]ìš”ì²­/ì‘ë‹µ:[/bold] {req_count}/{resp_count}",
            f"âŒ  [bold]ì—ëŸ¬:[/bold] [bold red]{err_count}[/bold red]ê±´",
        ]
        
        self.console.print()
        self.console.print(Panel(
            "\n".join(result_lines),
            title="[bold green]âœ¨ Crawling Completed[/bold green]",
            border_style="green",
            padding=(0, 1),
            width=50,
        ))

    def request_scheduled(self, request, spider):
        """Update status on request schedule (First req = Tor conn)."""
        if not self.first_response:
            new_text = "[yellow]ğŸŒ Tor ì—°ê²° ì¤‘...[/yellow]"
            if self.last_item_text != new_text:
                self.last_item_text = new_text
                # Live refresh loop will pick this up; no need to force update on every request
                # which causes flooding if many requests are scheduled at once.

    def item_scraped(self, item, spider):
        """Update status on item scrape."""
        title = item.get("title", "")[:30]
        self.last_item_text = f"[cyan]â³ í¬ë¡¤ë§ ì¤‘[/cyan] | [green]âœ… ìˆ˜ì§‘: {title}[/green]"
        self._update_status()

    def item_dropped(self, item, response, exception, spider):
        """Update status on item drop."""
        title = item.get("title", "")[:30] if hasattr(item, "get") else str(item)[:30]
        self.last_item_text = f"[cyan]â³ í¬ë¡¤ë§ ì¤‘[/cyan] | [dim]ğŸ”„ ìŠ¤í‚µ: {title}[/dim]"
        self._update_status()

    def response_received(self, response, request, spider):
        """Update status on response received."""
        if not self.first_response:
            self.first_response = True
            self.last_item_text = "[cyan]â³ í¬ë¡¤ë§ ì¤‘...[/cyan]"
        self._update_status()

    def _update_status(self):
        """Update progress bar status text."""
        if self.task_id is None:
            return
            
        scraped = self.stats.get_value("item_scraped_count", 0)
        dropped = self.stats.get_value("item_dropped_count", 0)
        req_count = self.stats.get_value("downloader/request_count", 0)
        err_count = self.stats.get_value("log_count/ERROR", 0)

        pre_dedup = self.stats.get_value('pre_dedup/skipped', 0)

        info_text = (
            f"ğŸ“¦ [green]{scraped}[/green] | "
            f"ğŸ”„ {pre_dedup} | "
            f"ğŸ—‘ï¸ {dropped} | "
            f"ğŸŒ {req_count} | "
            f"âŒ [red]{err_count}[/red]"
        )

        self.progress.update(self.task_id, info=info_text)
        
        # Live ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        if self.live:
            self.live.update(self._build_display())

