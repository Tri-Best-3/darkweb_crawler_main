# TriCrawl Usage Guide (ì‚¬ìš©ì ê°€ì´ë“œ)

This document provides a detailed guide on how to use the TriCrawl CLI and its features.
(ì´ ë¬¸ì„œëŠ” TriCrawl CLI ë° ì£¼ìš” ê¸°ëŠ¥ì˜ ìƒì„¸ ì‚¬ìš©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.)

## CLI Main Menu (ë©”ì¸ ë©”ë‰´)

Run `python main.py` to enter the interactive CLI.

### 1. ğŸŒ‘ Start Crawl
- **Function**: Runs a one-time crawl job.
- **Process**: 
    1. Checks Tor connection.
    2. Asks for the target spider (or 'ALL').
    3. Executes `scrapy crawl` inside a Docker container.
    4. Shows execution summary and stats after completion.
- **ì„¤ëª…**: ì¼íšŒì„± í¬ë¡¤ë§ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. Tor ì—°ê²°ì„ í™•ì¸í•˜ê³ , íƒ€ê²Ÿ ìŠ¤íŒŒì´ë”ë¥¼ ì„ íƒí•˜ì—¬ Docker ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ í¬ë¡¤ëŸ¬ë¥¼ êµ¬ë™í•©ë‹ˆë‹¤. ì™„ë£Œ í›„ ìš”ì•½ í†µê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

### 2. ğŸ“¡ Monitoring Mode
- **Function**: Runs an automated scheduler loop with a real-time dashboard.
- **Features**:
    - **Countdown**: Visual countdown to the next run.
    - **Status Panel**: Shows current interval, target, and log file path.
    - **Live Logs**: Displays the current status of the scheduler.
- **Configuration**:
    - You can set the Interval (1h~24h), Target, and Reference Start Time via the sub-menu.
    - **Defaults**: The initial settings are loaded from `config/scheduler_state.json`.
        - Note: This file is **read-only** by default. To change startup defaults, edit this file manually.
- **ì„¤ëª…**: ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œì™€ í•¨ê»˜ ìë™ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    - **ê¸°ëŠ¥**: ë‹¤ìŒ ì‹¤í–‰ê¹Œì§€ ë‚¨ì€ ì‹œê°„ì„ ì¹´ìš´íŠ¸ë‹¤ìš´í•˜ê³ , í˜„ì¬ ì„¤ì • ìƒíƒœì™€ ë¡œê·¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
    - **ì„¤ì •**: ì„œë¸Œ ë©”ë‰´ì—ì„œ ì‹¤í–‰ ì£¼ê¸°(1ì‹œê°„~24ì‹œê°„), íƒ€ê²Ÿ, ì‹œì‘ ê¸°ì¤€ ì‹œê°„ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - **ì´ˆê¸°ê°’**: í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ `config/scheduler_state.json` íŒŒì¼ì—ì„œ ê¸°ë³¸ ì„¤ì •ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ì´ íŒŒì¼ì€ ê¸°ë³¸ì ìœ¼ë¡œ **ì½ê¸° ì „ìš©**ì´ë©°, ì´ˆê¸°ê°’ì„ ì˜êµ¬ì ìœ¼ë¡œ ë°”ê¾¸ê³  ì‹¶ì„ ë•Œë§Œ ì§ì ‘ ìˆ˜ì •í•˜ì„¸ìš”.

### 3. ğŸ”¬ Open Dashboard
- Opens the Apache Superset dashboard in your default browser.
- Requires `SUPERSET_CLOUD_URL` or local Superset setup.
- **ì„¤ëª…**: ê¸°ë³¸ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ Apache Superset ëŒ€ì‹œë³´ë“œë¥¼ ì—½ë‹ˆë‹¤. `.env`ì— `SUPERSET_CLOUD_URL`ì´ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

### 4. ğŸ“„ View Logs
- Opens the log file of the *last run* (`tricrawl/logs/last_run.log`) using the system's default text editor (Notepad, etc.).
- **ì„¤ëª…**: ê°€ì¥ ìµœê·¼ì— ì‹¤í–‰ëœ ë¡œê·¸ íŒŒì¼(`tricrawl/logs/last_run.log`)ì„ ì‹œìŠ¤í…œ ê¸°ë³¸ í…ìŠ¤íŠ¸ í¸ì§‘ê¸°(ë©”ëª¨ì¥ ë“±)ë¡œ ì—½ë‹ˆë‹¤.

### 5. ğŸ³ Start Docker
- Runs `docker-compose up -d` to start the Tor Proxy and Superset/Supabase containers.
- **Must be run before crawling.**
- **ì„¤ëª…**: `docker-compose up -d` ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ Tor í”„ë¡ì‹œì™€ DB ì»¨í…Œì´ë„ˆë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. **í¬ë¡¤ë§ ì „ì— ë°˜ë“œì‹œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.**

### 6. ğŸ›‘ Stop Docker
- Runs `docker-compose down` to stop all containers and free resources.
- **ì„¤ëª…**: ëª¨ë“  Docker ì»¨í…Œì´ë„ˆë¥¼ ì¤‘ì§€í•˜ê³  ë¦¬ì†ŒìŠ¤ë¥¼ í•´ì œí•©ë‹ˆë‹¤.

### 7. ğŸ’¾ Export DB
- Exports data from Supabase to local JSONL and CSV files in `tricrawl/data/`.
- **ì„¤ëª…**: Supabase DBì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¡œì»¬ì˜ `tricrawl/data/` í´ë”ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤ (JSONL/CSV í˜•ì‹).

### 8. ğŸ”” Toggle Discord
- Toggles the `DISCORD_ENABLED` setting in `.env`.
- Useful for silencing notifications during testing.
- **ì„¤ëª…**: `.env` íŒŒì¼ì˜ `DISCORD_ENABLED` ì„¤ì •ì„ ì¼œê±°ë‚˜ ë•ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì¤‘ì— ì•Œë¦¼ì„ ì ì‹œ ë„ê³  ì‹¶ì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

---

## Configuration Files (ì„¤ì • íŒŒì¼)

### 1. `config/scheduler_state.json`
Defines the **default settings** for Monitoring Mode.
(ëª¨ë‹ˆí„°ë§ ëª¨ë“œ ì§„ì… ì‹œ ì‚¬ìš©ë  ê¸°ë³¸ê°’ì„ ì •ì˜í•©ë‹ˆë‹¤.)

```json
{
  "interval_hours": 1,        // Execution interval (hours) / ì‹¤í–‰ ì£¼ê¸° (ì‹œê°„)
  "target": "ALL",            // Target spider name or "ALL" / ì‹¤í–‰ ëŒ€ìƒ
  "ref_start_time": null,     // Optional start time (YYYY-MM-DD HH:MM) / ì‹œì‘ ê¸°ì¤€ ì‹œê°„ (ì˜µì…˜)
  "cycle_count": 0            // (Unused) / ë¯¸ì‚¬ìš©
}
```

### 2. `config/crawler_config.yaml`
Defines global crawling behavior (timeouts, retries).
(í¬ë¡¤ë§ íƒ€ì„ì•„ì›ƒ, ì¬ì‹œë„ íšŸìˆ˜ ë“± ë™ì‘ì„ ì •ì˜í•©ë‹ˆë‹¤.)

```yaml
global:
  days_to_crawl: 3        # Crawl posts from the last N days / ìµœê·¼ Nì¼ì¹˜ ê²Œì‹œë¬¼ë§Œ ìˆ˜ì§‘
  timeout_seconds: 60     # Request timeout / ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
  max_retries: 2          # Max retries on failure / ì‹¤íŒ¨ ì‹œ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

spiders:
  lockbit:
    timeout_seconds: 120  # Spider-specific override / íŠ¹ì • ìŠ¤íŒŒì´ë” ê°œë³„ ì„¤ì •
```

---

## Troubleshooting (íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

- **Tor Connection Failed**:
    - Ensure Docker is running (Menu 5).
    - Wait 1-2 minutes for Tor to build circuits.
    - Check logs: `docker logs tricrawl-tor`.
    - **Tor ì—°ê²° ì‹¤íŒ¨**: Dockerê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”(5ë²ˆ ë©”ë‰´). Tor íšŒë¡œ êµ¬ì„±ì— 1~2ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **Dashboard Not Opening**:
    - Check if `SUPERSET_CLOUD_URL` is set in `.env`.
    - If running locally, ensure the Superset container is up.
    - **ëŒ€ì‹œë³´ë“œ ì•ˆ ì—´ë¦¼**: `.env` íŒŒì¼ì— `SUPERSET_CLOUD_URL`ì´ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
